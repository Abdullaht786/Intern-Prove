# -*- coding: utf-8 -*-
"""Twitter Sentiment Analysis|NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/twitter-sentiment-analysis-nlp-449ca14d-decf-49dc-9f58-5378cb372f98.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240929/auto/storage/goog4_request%26X-Goog-Date%3D20240929T093605Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D324e21e13c46acfd087e10f0a20e14ea28f165f1990f87ae8507f846c03a1256f780f5a5831bc7bd436cf0e4bf638070f17f5fd946add200d161f2a57f24d1023ebb5b00b6f8cec0564b31fe152638842e834970ec5e2e171b81c642a823cdafa0977494ff3296bc124759fb8ea8753be01ff4aa3ae8357b360814add2a1f8adb8b24f1c453a9b127911757765ddb465900aed5b463593cf0ddc225fa16a2e9bd964be462ca7ce36fe975fa1ccbcae1b79db4ad00d424128a3d8a34401f503fa3ea704fba201f20d1982767a069f975162ebfba1be0f4fa4b8cefb1dbabda329fb4ba1a12f9d84f33245f1f6cffe6c1d22d8352e4b848e5575ec3288c7f15726
"""



"""# Import Libraries"""

import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report


from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

import spacy

import warnings
warnings.filterwarnings('ignore')

"""# Explore Data"""

col = ['id','country','Label','Text']
data = pd.read_csv("/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv", names=col)

data.head()

data.tail()

data.shape

data.info()

data['Label'].value_counts()

print(f"{data['Text'][2]} -> {data['Label'][2]}")

"""# Preprocessing"""

data.dropna(inplace=True)

# Preprocess Function
nlp = spacy.load("en_core_web_sm")
def preprocess(text):
    doc = nlp(text)
    filtered_tokens = []
    for token in doc:
        if token.is_stop or token.is_punct:
            continue
        filtered_tokens.append(token.lemma_)

    return " ".join(filtered_tokens)

data['Preprocessed Text'] = data['Text'].apply(preprocess)

data

# Encoding target column
le = LabelEncoder()
data['Label'] = le.fit_transform(data['Label'])

data

# Split data into train and test

x_train, x_test, y_train, y_test = train_test_split(data['Preprocessed Text'], data['Label'],
                                                    test_size=0.2, random_state=42, stratify=data['Label'])

x_test.shape

x_train.shape

"""# ML Model

#### Naive Bayes
"""

# classifier
clf = Pipeline([
    ('vectorizer_tri_grams', TfidfVectorizer()),
    ('naive_bayes', (MultinomialNB()))
])

clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(accuracy_score(y_test, y_pred))

print(classification_report(y_test, y_pred))

"""#### Random Forest"""

clf = Pipeline([
    ('vectorizer_tri_grams', TfidfVectorizer()),
    ('naive_bayes', (RandomForestClassifier()))
])

clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print(accuracy_score(y_test, y_pred))

print(classification_report(y_test, y_pred))

"""# Testing"""

test_data = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', names=col)

test_data.head()

test_txt = test_data['Text'][25]
print(f"{test_txt} ===> {test_data['Label'][25]}")

# Apply preprocess

test_txt_processed = [preprocess(test_txt)]
test_txt_processed

# Get Prediction

test_txt = clf.predict(test_txt_processed)

classes = ['Irrelevant', 'Natural', 'Negative', 'Positive']

print(f"True Label: {test_data['Label'][25]}")
print(f'Predict Label: {classes[test_txt[0]]}')

